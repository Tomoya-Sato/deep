{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹å›å¸°ã€€(softmax regression)ã®å®Ÿè£…\n",
    "# ç›®æ¬¡\n",
    "1. æ¦‚è¦\n",
    "- ç›®æ¨™\n",
    "- ä¸‹æº–å‚™\n",
    "- softmaxé–¢æ•°ã®å®Ÿè£…\n",
    "- å¤šã‚¯ãƒ©ã‚¹äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼èª¤å·®ã®å®Ÿè£…\n",
    "- ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹å›å¸°ã‚¯ãƒ©ã‚¹ã®å®Ÿè£…\n",
    "- å­¦ç¿’\n",
    "\n",
    "# 1. æ¦‚è¦\n",
    "- ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã®ä¸€èˆ¬åŒ–ã§ï¼Œå¤šã‚¯ãƒ©ã‚¹ã«å¯¾å¿œã—ãŸæ‰‹æ³•\n",
    "- Kå€‹ã®ã‚¯ãƒ©ã‚¹è­˜åˆ¥å•é¡Œã‚’è€ƒãˆã‚‹ï¼$\\boldsymbol{x}$ï¼šå…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼Œ$\\boldsymbol{t}$ï¼šæ•™å¸«ãƒ‡ãƒ¼ã‚¿\n",
    "\n",
    "\\begin{align}\n",
    "\\it{D}=\\left\\{\\left(\\boldsymbol{x}_i,\\boldsymbol{t}_i\\right)\\right\\}_{i=1}^{N}\\, ,\\boldsymbol{x}\\in\\mathbb{R}^d,\\, \\boldsymbol{t}\\in\\left\\{1,\\cdots,K\\right\\}\n",
    "\\end{align}\n",
    "\n",
    "- å„ã‚¯ãƒ©ã‚¹ã®äº‹å¾Œç¢ºç‡ã‚’æ±‚ã‚ã‚‹ï¼å„ã‚¯ãƒ©ã‚¹ã”ã¨ã«é‡ã¿è¡Œåˆ— $\\boldsymbol{w}^{(ğ‘—)}$ã‚’æŒã¤ï¼\n",
    "$$\n",
    "P(y=1|\\,\\boldsymbol{x})=\\frac{\\exp({\\boldsymbol{w}^{(1)\\top}\\boldsymbol{x}})}{\\sum_{j=1}^{K}\\exp{(\\boldsymbol{w}^{(j)\\top}\\boldsymbol{x}})}\\\\\n",
    "P(y=2|\\,\\boldsymbol{x})=\\frac{\\exp({\\boldsymbol{w}^{(2)\\top}\\boldsymbol{x}})}{\\sum_{j=1}^{K}\\exp{(\\boldsymbol{w}^{(j)\\top}\\boldsymbol{x}})}\\\\\n",
    "\\vdots\\\\\n",
    "P(y=K|\\,\\boldsymbol{x})=\\frac{\\exp({\\boldsymbol{w}^{(K)\\top}\\boldsymbol{x}})}{\\sum_{j=1}^{K}\\exp{(\\boldsymbol{w}^{(j)\\top}\\boldsymbol{x}})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ç›®æ¨™\n",
    "- ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹å›å¸°ã‚’å®Ÿè£…ã—ã¦ï¼Œmnistï¼ˆæ‰‹æ›¸ãæ•°å­—ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰ã‚’è­˜åˆ¥ã™ã‚‹ï¼\n",
    "- ã¾ãš**æ´»æ€§åŒ–é–¢æ•°**ã®ä¸€ç¨®ã§ã‚ã‚‹**softmax**é–¢æ•°ã¨ï¼Œ**äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼é–¢æ•°**ã‚’å®Ÿè£…ã™ã‚‹ï¼ãã®å¾Œç¢ºç‡**çš„å‹¾é…é™ä¸‹æ³•**ã‚’å®Ÿè£…ã—ï¼Œ**SoftmaxRegression**ã‚¯ãƒ©ã‚¹ã‚’å®Ÿè£…ã™ã‚‹ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ä¸‹æº–å‚™\n",
    "## 3.1 ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "- matplotlib: å›³ã‚„ã‚°ãƒ©ãƒ•ã®æç”»ãªã©ï¼\n",
    "- numpy: è¡Œåˆ—æ¼”ç®—ãªã©\n",
    "- sklearn: scikit-learnï¼æ§˜ã€…ãªæ©Ÿæ¢°å­¦ç¿’ã®ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ã§ãã‚‹ãŒï¼Œä»Šå›ã¯MNISTã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã®ã«ç”¨ã„ã‚‹ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from __future__ import print_function\n",
    "from test_softmax import *  # ãƒ†ã‚¹ãƒˆç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 MNISTãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n",
    "- ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ï¼ä¸€åº¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ï¼Œãã®å¾Œã¯ãƒ‡ãƒ¼ã‚¿ã‚’å‚ç…§ã—ã¦èª­ã¿è¾¼ã‚“ã§ãã‚Œã‚‹ã®ã§ï¼Œæ¯å›ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãªãã¦ã‚‚è‰¯ããªã‚‹ï¼\n",
    "- XãŒç”»åƒãƒ‡ãƒ¼ã‚¿ï¼ŒYãŒæ­£è§£ãƒ‡ãƒ¼ã‚¿\n",
    "- mnistã®ãƒ‡ãƒ¼ã‚¿ã¯ï¼Œ0~255ã®intå‹ã§è¡¨ã•ã‚Œã¦ã„ã‚‹ãŒï¼Œã“ã‚Œã‚’**255ã§å‰²ã£ã¦**æ­£è¦åŒ–ã™ã‚‹ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original', data_home='./data/')\n",
    "X, Y = mnist.data, mnist.target\n",
    "X = X / 255.\n",
    "Y = Y.astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f344dcd0910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X[i * 6500].reshape(28, 28), cmap='gray_r')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å­¦ç¿’ç”¨ãƒ»ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²\n",
    "- è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ï¼ŒåŒã˜è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§æ€§èƒ½ã®è©•ä¾¡ã‚’è¡Œã†ã¨ï¼Œè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã¯è‰¯ã„æ€§èƒ½ã‚’ç¤ºã™ãŒï¼Œãƒ‡ãƒ¼ã‚¿ã‚’å°‘ã—ã§ã‚‚å¤‰ãˆã‚‹ã¨æ€§èƒ½ãŒä½ä¸‹ã—ã¦ã—ã¾ã†ã“ã¨ãŒã‚ã‚‹ï¼ˆ**éå­¦ç¿’**ï¼‰ï¼\n",
    "- ã‚ˆã£ã¦ï¼Œå­¦ç¿’ã™ã‚‹è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ã¯ç•°ãªã‚‹ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æ€§èƒ½è©•ä¾¡ã‚’è¡Œã†ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "train_y = np.eye(10)[train_y].astype(np.int32)\n",
    "test_y = np.eye(10)[test_y].astype(np.int32)\n",
    "train_n = train_x.shape[0]\n",
    "test_n = test_x.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. softmaxé–¢æ•°ã®å®Ÿè£…\n",
    "æ´»æ€§åŒ–é–¢æ•°ã®ä¸€ç¨®ã§ã‚ã‚‹softmaxé–¢æ•°ã‚’å®Ÿè£…ã™ã‚‹ï¼\n",
    "- é–¢æ•°ï¼šsoftmax\n",
    "    - å…¥åŠ›ï¼š$\\boldsymbol{X}=(\\boldsymbol{x_1},\\boldsymbol{x_2},\\cdots,\\boldsymbol{x_N})^\\top\\in\\mathbb{R}^{N\\times K}$\n",
    "\n",
    "    - å‡ºåŠ›ï¼š$\\boldsymbol{Y}=(\\boldsymbol{y_1},\\boldsymbol{y_2},\\cdots,\\boldsymbol{y_N})^\\top\\in\\mathbb{R}^{N\\times K},\\,\\,\\,y_{nk} = softmax(\\boldsymbol{x_n})_k$\n",
    "    - ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã‚’é˜²ããŸã‚ã«$\\boldsymbol{x}_n$ã®æœ€å¤§å€¤ã‚’$\\boldsymbol{x}_n$è‡ªèº«ã‹ã‚‰å¼•ã\n",
    "$$\n",
    "\\begin{align}\n",
    "softmax(\\boldsymbol{x})_k&= \\frac{\\exp (x_{k})} {\\Sigma_{i=1}^{K}{\\exp (x_{i})}}\\\\\n",
    "&=\\frac{\\exp (-x_{max})\\exp (x_{k})}{\\exp (-x_{max})\\Sigma_{i=1}^{K}{\\exp (x_{i})}}=\\frac{\\exp (x_{k}-x_{max})} {\\Sigma_{i=1}^{K}{\\exp (x_{i}-x_{max})}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "ãƒ’ãƒ³ãƒˆ\n",
    "</summary>\n",
    "<ol>\n",
    "    <li>æœ€å¤§å€¤\n",
    "    <ul> \n",
    "        <li>```axis=1```ã‚’æŒ‡å®šã™ã‚‹ã¨ãƒ‡ãƒ¼ã‚¿$\\boldsymbol{x_n}$ã”ã¨ã«æœ€å¤§å€¤ã‚’è¨ˆç®—ã§ãã‚‹</li>\n",
    "        <li>è¡Œåˆ—ã®shapeã‚’å¤‰ãˆãŸããªã„å ´åˆã¯ï¼Œ```keepdims=True```ã‚’æŒ‡å®šã™ã‚‹</li>\n",
    "    </ul></li>\n",
    "    <li>$\\exp$\n",
    "    <ul>\n",
    "    <li>```np.exp()```</li>\n",
    "    </ul></li>\n",
    "    <li>åˆè¨ˆ\n",
    "    <ul>\n",
    "    <li>```np.sum()```</li>\n",
    "    <li>```axis=1```ã‚’æŒ‡å®šã™ã‚‹ã¨ãƒ‡ãƒ¼ã‚¿$\\boldsymbol{x_n}$ã”ã¨ã«åˆè¨ˆã‚’è¨ˆç®—ã§ãã‚‹</li>\n",
    "    <li>è¡Œåˆ—ã®shapeã‚’å¤‰ãˆãŸããªã„å ´åˆã¯ï¼Œ```keepdims=True```ã‚’æŒ‡å®šã™ã‚‹</li>\n",
    "    </ul></li>\n",
    "</ol>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    y = np.zeros(x.shape)\n",
    "    y = np.exp(x - np.amax(x, axis=1, keepdims=True)) / np.sum(np.exp(x - np.amax(x, axis=1, keepdims=True)), axis=1, keepdims=True)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ†ã‚¹ãƒˆï¼ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok!\n"
     ]
    }
   ],
   "source": [
    "test_softmax(softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. å¤šã‚¯ãƒ©ã‚¹ã®äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼èª¤å·®ã®å®Ÿè£…\n",
    "- é–¢æ•°ï¼šcross_entropy\n",
    "    - å…¥åŠ›ï¼š $Y=(\\boldsymbol{y}_1,\\boldsymbol{y}_2,\\cdots,\\boldsymbol{y}_N)^\\top\\in \\mathbb{R}^{N\\times K}$, \n",
    "$T=(\\boldsymbol{t}_1,\\boldsymbol{t}_2,\\cdots,\\boldsymbol{t}_N)^\\top\\in \\mathbb{R}^{N\\times K}$<br />\n",
    "$\\boldsymbol{y}_n$ã¯ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹é–¢æ•°ã®å‡ºåŠ›ï¼Œ$\\boldsymbol{t}_n$ã¯æ•™å¸«ãƒ©ãƒ™ãƒ«(1-of-Kè¡¨ç¾)\n",
    "\n",
    "    - å‡ºåŠ›ï¼š \n",
    "    $$L=-\\frac{1}{N}\\sum_{n=1}^N \\sum_i \\boldsymbol t_{n,i} \\log \\boldsymbol y_{n,i}\\in\\mathbb{R}^1\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "ãƒ’ãƒ³ãƒˆ\n",
    "</summary>\n",
    "<ol>\n",
    "    <li>$\\log$\n",
    "    <ul> \n",
    "        <li>```np.log()```</li>\n",
    "    </ul></li>\n",
    "    <li>åˆè¨ˆ\n",
    "    <ul>\n",
    "    <li>```np.sum()```</li>\n",
    "    </ul></li>\n",
    "    <li>å¹³å‡\n",
    "    <ul>\n",
    "    <li>```np.mean()```</li>\n",
    "    </ul></li>\n",
    "</ol>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y, t):\n",
    "    L = - np.mean(np.sum(t * np.log(y), axis=1, keepdims=True), axis=0)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ†ã‚¹ãƒˆï¼ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok!\n"
     ]
    }
   ],
   "source": [
    "test_cross_entropy(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹å›å¸°ã®å®Ÿè£…\n",
    "ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹å›å¸°ã‚¯ãƒ©ã‚¹ã‚’å®Ÿè£…ã™ã‚‹ï¼\n",
    "## 6.1 å‹¾é…é™ä¸‹æ³•ã®å®Ÿè£…\n",
    "SoftmaxRegressionã‚¯ãƒ©ã‚¹ã®gradient_decenté–¢æ•°ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ï¼\n",
    "- é–¢æ•°ï¼šgradient_descent  \n",
    "    - å…¥åŠ›ï¼š\n",
    "        - å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼š $\\boldsymbol{X}\\in\\mathbb{R}^{N\\times D}$\n",
    "        - äºˆæ¸¬ãƒ©ãƒ™ãƒ«ï¼š$\\boldsymbol{Y}\\in\\mathbb{R}^{N\\times K}$\n",
    "        - æ•™å¸«ãƒ©ãƒ™ãƒ«ï¼š$\\boldsymbol{T}\\in\\mathbb{R}^{N\\times K}$\n",
    "        - å­¦ç¿’ç‡ï¼š$\\epsilon \\in \\mathbb{R}$\n",
    "    - æ›´æ–°ï¼š\n",
    "        - é‡ã¿ã¨ãƒã‚¤ã‚¢ã‚¹ $\\boldsymbol{W},\\,\\boldsymbol{b}$\n",
    "        \n",
    "- å‹¾é…é™ä¸‹æ³•: ï¼ˆ$\\boldsymbol{W},\\boldsymbol{b}$ï¼šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼Œ$\\epsilon$ï¼šå­¦ç¿’ç‡ï¼‰\n",
    "$$\n",
    "\\boldsymbol{W}\\leftarrow\\boldsymbol{W}-\\epsilon\\nabla_{\\boldsymbol{W}}L\\\\\n",
    "\\boldsymbol{b}\\leftarrow\\boldsymbol{b}-\\epsilon\\nabla_{\\boldsymbol{b}}L\n",
    "$$\n",
    "- ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹å›å¸°ã®å‹¾é… :\n",
    "\\begin{align}\n",
    "\\nabla_{\\boldsymbol{W}}L&=\\frac{1}{N}\\boldsymbol{X}^\\top(\\boldsymbol{Y}-\\boldsymbol{T})\\\\\n",
    "\\nabla_{\\boldsymbol{b}}L&=\\frac{1}{N}(1,1,...,1)(\\boldsymbol{Y}-\\boldsymbol{T})\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "ãƒ’ãƒ³ãƒˆ\n",
    "</summary>\n",
    "<ol>\n",
    "    <li>è¡Œåˆ—ã®ç©\n",
    "    <ul> \n",
    "        <li>```np.dot()```</li>\n",
    "    </ul></li>\n",
    "    <li>åˆè¨ˆ\n",
    "    <ul>\n",
    "    <li>```np.sum()```</li>\n",
    "    </ul></li>\n",
    "</ol>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegression:\n",
    "    def __init__(self, n_in, n_out):\n",
    "        self.W = np.random.uniform(0.08, -0.08, (n_in, n_out)) #å‹¾é…ã®åˆæœŸåŒ–\n",
    "        self.b = np.zeros(n_out) #ãƒã‚¤ã‚¢ã‚¹ã®åˆæœŸåŒ–\n",
    "        \n",
    "    def gradient_decent(self, X, Y, T, eps):\n",
    "        batchsize = X.shape[0]\n",
    "        self.W = self.W - eps * np.dot(X.T, (Y - T)) / batchsize\n",
    "        self.b = self.b - eps * np.sum((Y - T), axis=0) / batchsize\n",
    "        \n",
    "    def train(self, x, t, lr):\n",
    "        y = softmax(np.dot(x, self.W) + self.b) #äºˆæ¸¬\n",
    "        self.gradient_decent(x, y, t, lr) #ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ›´æ–°\n",
    "        loss = cross_entropy(y, t) #ãƒ­ã‚¹ã®ç®—å‡º\n",
    "        return y, loss\n",
    "\n",
    "    def test(self, x, t):\n",
    "        y = softmax(np.dot(x, self.W) + self.b) #äºˆæ¸¬\n",
    "        loss = cross_entropy(y, t) #ãƒ­ã‚¹ã®ç®—å‡º\n",
    "        return y, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ†ã‚¹ãƒˆï¼ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok!\n"
     ]
    }
   ],
   "source": [
    "test_gradient_decent(SoftmaxRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. å­¦ç¿’\n",
    "## 7.1 ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–\n",
    "å…¥åŠ›ã¯784æ¬¡å…ƒï¼Œå‡ºåŠ›ã¯10æ¬¡å…ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftmaxRegression(784, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š\n",
    "- å­¦ç¿’epochæ•°ã¯20\n",
    "    - epochæ•°ã¨ã¯ï¼Œå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä½•å›å­¦ç¿’ã™ã‚‹ã‹ã‚’è¡¨ã™æ•°ã§ã‚ã‚‹ï¼\n",
    "- ãƒãƒƒãƒã‚µã‚¤ã‚ºã¯100\n",
    "    - ãƒŸãƒ‹ãƒãƒƒãƒã¨ã¯å°‘æ•°ã®ã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰ãªã‚‹é›†åˆã§ã‚ã‚‹ï¼\n",
    "- å­¦ç¿’ç‡ã¯1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 20\n",
    "batchsize = 100\n",
    "lr = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 å­¦ç¿’\n",
    "äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼èª¤å·®ã‚’ç¢ºç‡çš„å‹¾é…é™ä¸‹æ³•ã‚’ç”¨ã„ã¦æœ€å°åŒ–ã™ã‚‹ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 |ã€€Train loss 0.417, accuracy 0.8792 |ã€€Test loss 0.318, accuracy 0.9094\n",
      "epoch 1 |ã€€Train loss 0.314, accuracy 0.9100 |ã€€Test loss 0.366, accuracy 0.8897\n",
      "epoch 2 |ã€€Train loss 0.302, accuracy 0.9140 |ã€€Test loss 0.295, accuracy 0.9194\n",
      "epoch 3 |ã€€Train loss 0.295, accuracy 0.9166 |ã€€Test loss 0.295, accuracy 0.9196\n",
      "epoch 4 |ã€€Train loss 0.288, accuracy 0.9189 |ã€€Test loss 0.295, accuracy 0.9169\n",
      "epoch 5 |ã€€Train loss 0.286, accuracy 0.9191 |ã€€Test loss 0.296, accuracy 0.9202\n",
      "epoch 6 |ã€€Train loss 0.282, accuracy 0.9199 |ã€€Test loss 0.296, accuracy 0.9209\n",
      "epoch 7 |ã€€Train loss 0.280, accuracy 0.9208 |ã€€Test loss 0.290, accuracy 0.9186\n",
      "epoch 8 |ã€€Train loss 0.279, accuracy 0.9208 |ã€€Test loss 0.289, accuracy 0.9209\n",
      "epoch 9 |ã€€Train loss 0.277, accuracy 0.9207 |ã€€Test loss 0.296, accuracy 0.9188\n",
      "epoch 10 |ã€€Train loss 0.275, accuracy 0.9230 |ã€€Test loss 0.290, accuracy 0.9223\n",
      "epoch 11 |ã€€Train loss 0.274, accuracy 0.9224 |ã€€Test loss 0.323, accuracy 0.9080\n",
      "epoch 12 |ã€€Train loss 0.273, accuracy 0.9229 |ã€€Test loss 0.298, accuracy 0.9179\n",
      "epoch 13 |ã€€Train loss 0.271, accuracy 0.9234 |ã€€Test loss 0.300, accuracy 0.9178\n",
      "epoch 14 |ã€€Train loss 0.272, accuracy 0.9232 |ã€€Test loss 0.338, accuracy 0.9031\n",
      "epoch 15 |ã€€Train loss 0.270, accuracy 0.9240 |ã€€Test loss 0.286, accuracy 0.9230\n",
      "epoch 16 |ã€€Train loss 0.268, accuracy 0.9248 |ã€€Test loss 0.307, accuracy 0.9149\n",
      "epoch 17 |ã€€Train loss 0.267, accuracy 0.9243 |ã€€Test loss 0.311, accuracy 0.9146\n",
      "epoch 18 |ã€€Train loss 0.267, accuracy 0.9247 |ã€€Test loss 0.297, accuracy 0.9194\n",
      "epoch 19 |ã€€Train loss 0.266, accuracy 0.9246 |ã€€Test loss 0.304, accuracy 0.9161\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epoch):\n",
    "    print ('epoch %d |ã€€' % epoch, end=\"\")\n",
    "    \n",
    "    # Training\n",
    "    sum_loss = 0\n",
    "    pred_label = []\n",
    "    perm = np.random.permutation(train_n) #ãƒ©ãƒ³ãƒ€ãƒ ã«ä¸¦ã³æ›¿ãˆã‚‹\n",
    "    \n",
    "    for i in range(0, train_n, batchsize): #ãƒŸãƒ‹ãƒãƒƒãƒã”ã¨ã«å­¦ç¿’ã‚’è¡Œã†\n",
    "        x = train_x[perm[i:i+batchsize]]\n",
    "        y = train_y[perm[i:i+batchsize]]\n",
    "        \n",
    "        pred, loss = model.train(x, y, lr)\n",
    "        sum_loss += loss * x.shape[0]\n",
    "        # pred ã«ã¯ï¼Œ (N, 10)ã®å½¢ã§ï¼Œç”»åƒãŒ0~9ã®å„æ•°å­—ã®ã©ã‚Œã«åˆ†é¡ã•ã‚Œã‚‹ã‹ã®äº‹å¾Œç¢ºç‡ãŒå…¥ã£ã¦ã„ã‚‹\n",
    "        # ãã“ã§ï¼Œæœ€ã‚‚å¤§ãã„å€¤ã‚’ã‚‚ã¤ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—ã™ã‚‹ã“ã¨ã§ï¼Œè­˜åˆ¥çµæœã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã‚‹\n",
    "        pred_label.extend(pred.argmax(axis=1))\n",
    "\n",
    "    loss = sum_loss / train_n\n",
    "    # æ­£è§£ç‡\n",
    "    accu = accuracy_score(pred_label, np.argmax(train_y[perm], axis=1))\n",
    "    print('Train loss %.3f, accuracy %.4f |ã€€' %(loss, accu), end=\"\")\n",
    "    \n",
    "    \n",
    "    # Testing\n",
    "    sum_loss = 0\n",
    "    pred_label = []\n",
    "    \n",
    "    for i in range(0, test_n, batchsize):\n",
    "        x = test_x[i: i+batchsize]\n",
    "        y = test_y[i: i+batchsize]\n",
    "        \n",
    "        pred, loss = model.test(x, y)\n",
    "        sum_loss += loss * x.shape[0]\n",
    "        pred_label.extend(pred.argmax(axis=1))\n",
    "        \n",
    "    loss = sum_loss / test_n\n",
    "    \n",
    "    accu = accuracy_score(pred_label, np.argmax(test_y, axis=1))\n",
    "    print('Test loss %.3f, accuracy %.4f' %(loss, accu) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ†ã‚¹ãƒˆã®æ­£è§£ç‡ãŒ92%ç¨‹åº¦ã«ãªã‚‹ã¨æˆåŠŸã§ã™ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
